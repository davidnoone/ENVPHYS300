{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidnoone/ENVPHYS300/blob/main/lab1_sea_level_rise_Assign.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qq8rFK9pdziM"
      },
      "source": [
        "# **ENVPHYS300 Lab 1: Python, Linear Regression, and Sea Level Rise**\n",
        "\n",
        "(Original by Kasper van Wijk, updated for 2025 by David Noone)\n",
        "\n",
        "The aim of this first lab is to become familiar with using Python to analyse and visualise scientific data. We will also fit some models to sea level data to explain trends over time.\n",
        "\n",
        "**Lab work and submission:** Complete all the exercises within the notebook itself, unless otherwise stated. Make sure you save the notebook (ideally to your Google Drive) before beginning, and save regularly throughout. You are encouraged to work on the problems together, but everyone will submit their own work. Submit your .ipynb notebook file along with any other files or data through Canvas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdsmU-yXdziV"
      },
      "source": [
        "First, we import the python libraries we'll use in this notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_OnEl9ndziW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd # pandas is a suite of tools to use on (csv) data\n",
        "import matplotlib.pyplot as plt # plotting tools\n",
        "import numpy as np # numerical tools\n",
        "import scipy.stats # this package has a pre-made linear regression function\n",
        "\n",
        "from scipy.optimize import curve_fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-Nn9sIjdziX"
      },
      "source": [
        "## Sea Level Data\n",
        "Sea level measurements for the Auckland harbour are averaged over the year to obtain a mean sea level and standard deviation.\n",
        "The data originates from LINZ.\n",
        "https://www.linz.govt.nz/products-services/data/types-linz-data/sea-level-data/long-term-annual-mean-sea-level-data\n",
        "\n",
        "Information about the data can be found in a REDAME file.\n",
        "https://www.linz.govt.nz/sites/default/files/data/Auckland_Readme.pdf\n",
        "\n",
        "\n",
        "The Python library [pandas](https://pandas.pydata.org) can easily read CSV data for us, without needing to know a lot of programming. Then we will convert the *pandas* data into a [NumPy](http://numpy.org) matrix, so we can easily work with the data throughout the rest of this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzV2yYtddziY"
      },
      "outputs": [],
      "source": [
        "#url=\"https://www.linz.govt.nz/sites/default/files/data/Auckland_Annual_MSL.csv\"\n",
        "url=\"https://www.linz.govt.nz/sites/default/files/2025-02/Auckland_Annual_MSL.csv\"    # here for the latest data\n",
        "\n",
        "\n",
        "harbour_data = pd.read_csv(url,delimiter=',',names=['year','MSL','err','comment'],skiprows=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTALCz4tefUK"
      },
      "source": [
        "There are a few years with no data. Here, we remove the lines with no data. This is quite tricky if you are new to pandas, or even python, so just bare with us:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBsJqDRqefUL"
      },
      "outputs": [],
      "source": [
        "harbour_data['MSL'].replace('', np.nan, inplace=True) # first we change all empty cells in the 'MSL' column with NaN (Not a Number)\n",
        "harbour_data.dropna(subset=['MSL'], inplace=True) # then, we remove all lines in the data frame that have an NaN in the 'MSL' column."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AY38WgOKefUL"
      },
      "source": [
        "There is a ton of things you can do directly with the dataframe harbour_data. You can access the different columns, like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvD7pWiyefUM"
      },
      "outputs": [],
      "source": [
        "harbour_data['year']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4JFzb6BefUM"
      },
      "source": [
        "Note that pandas is smart enough to recognize these values in the column 'year' are integers. Pandas has lots of options to work with these data, including plotting capabilities, but here we just take advantage of the ease of reading in data, and then we convert the columns to numpy arrays, with the to_numpy() attribute in pandas dataframes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waRlwCJeefUN"
      },
      "outputs": [],
      "source": [
        "time = harbour_data['year'].to_numpy()\n",
        "print(time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_4be-wedzia"
      },
      "source": [
        "#### Exercise 1\n",
        "In our case, the matrix has all the time data in the first column, all the sea level height in the second column, and the standard deviations in the third column. In the cell below, create three variables ```time```, ```height```, and ```errors```, and assign the correct data to each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deGIXA96dzib"
      },
      "outputs": [],
      "source": [
        "height =   # Extract the sea level data from the data frame and put the values in a numpy array\n",
        "errors =   # Extract the uncertainty in the sea level data from the data frame and put the values in a numpy array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tqFTTENdzid"
      },
      "source": [
        "Next, we will plot sea level in the Auckland Harbour, as a function of time, using [matplotlib](https://matplotlib.org/):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTCf2UV6dzif"
      },
      "outputs": [],
      "source": [
        "plt.errorbar(time, height, yerr=errors, color='r', ecolor='gray', marker='o', linestyle='')\n",
        "plt.grid()\n",
        "plt.xlabel('Date (year)')\n",
        "plt.ylabel('Mean Sea Level (m)')\n",
        "plt.title('Princes Wharf, Auckland (New Zealand)')\n",
        "plt.axis('tight')\n",
        "plt.savefig('test.png', bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1QbfS_sdzir"
      },
      "source": [
        "### Linear regression\n",
        "\n",
        "The value for mean sea level goes up and down, but clearly has a trend upwards. Let's see what the best fitting line is through these data.\n",
        "There are many ways to do such a linear regression, or more advanced polynomial fitting, in Python. Here's one example of linear regression from the stats functions in scipy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upx960A-dzir"
      },
      "outputs": [],
      "source": [
        "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(time, height)\n",
        "print(slope, intercept)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2oSfLKSefUP"
      },
      "source": [
        "#### Exercise 2\n",
        "Replot the data, adding the best-fitting line through these data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1xfK6YgefUP"
      },
      "outputs": [],
      "source": [
        "# write your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtfkjfScdzip"
      },
      "source": [
        "### Residuals or misfit\n",
        "#### Exercise 3\n",
        "The line looks like a reasonable representation of the data, but how did we do from a quantitative point of view? Let's compute the mean and standard deviation of the residual values (these are the values of the water depth minus the best fitting straight line through the data). Compute and print these values below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYEToR0Rdzip"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9vsLWq1dziq"
      },
      "source": [
        "#### Exercise 4\n",
        "If the regression did its job, the mean is practically zero. This means that any overshooting by the observations are balanced by undershootings. What did you find for the standard devation? What factors can you think of that contribute to the standard deviation? Type your responses in the box below: (Note, the scientists involved in collecting these data estimate the standard error in each of these annual means for sea level in Auckland is 2.5 cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4ytMWvidziq"
      },
      "source": [
        "<font color='red'>*Type your answers here*<font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t99Vi12Cdziq"
      },
      "source": [
        "If we were to feel that the linear model is a \"poor\" fit, one could always fit the data better with a model that has more degrees of freedom. Does this experiment warrant a quadratic term? Or even higher-order polynomials? Maybe not over these 100 years of data, but if the rise is due to climate change and we have positive feedbacks, maybe we should account for that in our model. In any case:\n",
        "\n",
        "**Given enough degrees of freedom in the model, we can fit the (any) data perfectly!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymZcI2eGdzit"
      },
      "source": [
        "If we decided to model the data with a polynomial instead of a straight line, then we could use the NumPy [polyfit](https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html) function. Here, we fit with a third-degree polynomial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nR4O1dkIdziu"
      },
      "outputs": [],
      "source": [
        "fit = np.polyfit(time, height, 3) #Least squares polynomial fit. Fit a polynomial p(x) = p[0] * x**deg + ... + p[deg] of degree deg to points (x, y).\n",
        "\n",
        "fit_poly = (fit[0] * time ** 3) + (fit[1] * time ** 2) + (fit[2] * time) + fit[3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3YP0IN3dziu"
      },
      "source": [
        "\n",
        "### Sea level rise in a time of climate change\n",
        "#### Exercise 5\n",
        "Australian scientists show historic data also support our linear regression results of a [1 to 2 mm/y rise in sea level](https://en.wikipedia.org/wiki/Sea_level_rise) averaged over the last 100+ years. However, tidal gauge and satellite data from the last decade(s) indicate sea level may now be rising at [double this rate](https://en.wikipedia.org/wiki/Sea_level_rise), according to the latest IPCC report! With this info, have another look at the Auckland data. Most sea level values in the 2000s falls *above* the regression line. It would require more than data from just one tidal gauge to attribute this significant, of course. Especially when you learn that the Auckland tidal gauge has been moved site three times since 2000. However, for the sake of a fitting exercise, write code to fit these data with a polynomial (see example above) and [an exponentional function](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html). Plot the data with the linear, polynomial, and exponential fits on the same plot, and caluclate the residuals for each of the fits.\n",
        "\n",
        "Hint: There are several ways to approach fitting an expoential. First, write down what the exponential function is! One way is to consider taking the log of this, which has the form of a line, and you can use a linear regression model.\n",
        "Another way is to do a non-linear fit. This can be done in python using the \"curve_fit\" function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LLlx3vqdziv"
      },
      "outputs": [],
      "source": [
        "# Write code here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOMqE7Yndziv"
      },
      "source": [
        "#### Exercise 6\n",
        "Are the polynomial residuals smaller than for a linear fit? How about the exponential residuals? Are any of the residuals closer to the reported standard error in the data? What do you conclude?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-WqW0W3dziw"
      },
      "source": [
        "<font color='red'>*Type your answers here*<font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoS1YAB21BHK"
      },
      "source": [
        "### Using multiple datasets to understand a trend\n",
        "As we have seen, it is often difficult to confirm or reject particular models based on one dataset. This is why geophysicists combine multiple different types of data to build a better picture of what is physically happening. However, it often takes a bit of geophysics detective work to prove or disprove a particular hypothesis...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyfDXikf3ll6"
      },
      "source": [
        "Is this trend different to what you would expect? What do you think could be causing this discrepancy? (Note: measurement error has been ruled out as a possible cause)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FDPnkKD4SUr"
      },
      "source": [
        "<font color='red'>*Type your answer here*<font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E82IeG9G4pBV"
      },
      "source": [
        "#### Final thoughts\n",
        "\n",
        "In order to confirm or deny our hypothesis for what we observe, we need to use a second type of data. One can locate and download a additional datasets that will help you explain the trend you observe in the sea level data. Explain why you chose this dataset in the space below. Some sources of sea level height can be found from the following links:\n",
        "\n",
        "[Map of sea level gauge locations in New Zealand](https://www.linz.govt.nz/sea/tides/sea-level-data/sea-level-data-downloads)\n",
        "\n",
        "[Map of geodetic sensors in New Zealand](https://www.geonet.org.nz/data/gnss/map)\n",
        "\n",
        "[Instructions for how to download data from GeoNet](https://fits.geonet.org.nz/api-docs/endpoint/observation)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}